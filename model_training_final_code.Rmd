---
title: "Final Project"
author: "Linh Tran"
date: "5/7/2021"
output: pdf_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggplot2)

library(caret)
library(glmnet)
library(mlbench)
library(e1071)
library(kernlab)
library(pROC) #generate ROC curve and calculate AUC 
library(ROCR)
library(vip) #variable importance plot: global impact on different predictor
library(pdp)
library(randomForest)
library(ranger)
library(AppliedPredictiveModeling) # for visualization purpose
library(corrplot)
library(RColorBrewer)
library(RANN)
library(visdat)
library(mgcv)
library(DMwR2)
library(lime)
library(grid)
library(naniar)
library(knitr)
library(kableExtra)
library(rpart.plot)
library(rpart)
library(party)
library(partykit)
library(plotmo)
library(ROSE)
library(iml)
library(gridExtra)
library(cowplot)
library(MASS)
library(klaR)

library(gbm)
library(imbalance)


knitr::opts_chunk$set(
  fig.width = 12,
  fig.height = 8,
  out.width = "90%"
)
```

# Import data

```{r data prep}
stroke_df = read.csv("./data/healthcare-dataset-stroke-data.csv")
# head(stroke_df)

head(stroke_df)

```





# EDA and Visualization

Distribution of stroke:

```{r}
dataplot10 = stroke_df %>% dplyr::count(stroke) 
dataplot1 = dataplot10 %>% mutate(ntotal=sum(dataplot10$n), perc= n/ntotal)
plot1= ggplot(dataplot1, aes(x="", y=perc*100, fill=as.factor(stroke), group=as.factor(stroke)))+theme_bw()+
  geom_bar(width = 1, stat = "identity") + theme_void() +
  labs(x=" ",y=" ", fill=" ") + 
  scale_fill_brewer(palette = "Dark2",labels = c("No stroke", "Stroke"))+
  geom_text( y=55, label="95.13 %", size=5)+geom_text(aes(label="4.87 %"),y=2.5, x=1.3, size=4)+
  coord_polar("y", start=0) + theme(legend.text=element_text(size=15))

plot1
```

We could see that only 4.87% of the 5110 individuals in the dataset suffered a stroke. \


```{r gender}
#genders

dataplot2=stroke_df %>% dplyr::count(stroke, gender) %>% spread(stroke, n)
names(dataplot2)=c("gender", "neg", "pos")

dataplot2 = dataplot2 %>% mutate(perc_gender=pos/(pos+neg))

plot2 = ggplot(dataplot2 %>% filter(gender!="Other"), aes(x=gender,
                        y=perc_gender*100, fill=as.factor(gender), 
                        group=as.factor(gender))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Gender",x="",y="Probability of stroke (%)") + scale_fill_brewer(palette = "Dark2") +
  theme(legend.position = "none")+  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))

```

Smoking status:

```{r smoking status}

dataplot3_1=stroke_df %>% dplyr::count(stroke, smoking_status) %>% spread(stroke, n)
names(dataplot3_1)=c("smoking_status", "neg", "pos")

dataplot3_1 = dataplot3_1 %>% mutate(perc_smoke=pos/(pos+neg))

plot3 = ggplot(dataplot3_1, aes(x=smoking_status,
                        y=perc_smoke*100, fill=as.factor(smoking_status), 
                        group=as.factor(smoking_status))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Smoking status",x=" ",y="Probability of stroke (%)") + scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(labels=c("formerly smoked" = "Formerly smoked", "never smoked" = "Never smoked", "smokes"="Smokes")) +
  theme(legend.position = "none")+  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))


```

People who identified as former smokers have the highest probability of having a stroke (~8%), followed by smokers and then people who never smoked.


```{r hypertension}
# hypertension

dataplot3_1a=stroke_df %>% dplyr::count(stroke, hypertension) %>% spread(stroke, n)
names(dataplot3_1a)=c("hypertension", "neg", "pos")

dataplot3_1a = dataplot3_1a %>% mutate(perc_hyp=pos/(pos+neg))

plot4 =ggplot(dataplot3_1a, aes(x=as.factor(hypertension) ,
                        y=perc_hyp*100, fill=as.factor(hypertension ), 
                        group=as.factor(hypertension ))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Hypertension", x=" ",y="Probability of stroke (%)", fill=" ") +
  scale_fill_brewer(palette = "Dark2") +
  scale_x_discrete(breaks=c("0","1"), labels=c("0" = "No hypertension", "1" = "Hypertension")) + theme(legend.position = "none")+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))



```


```{r heart disease}
#heart disease
dataplot3_1b=stroke_df %>% dplyr::count(stroke, heart_disease) %>% spread(stroke, n)
names(dataplot3_1b)=c("heart_disease", "neg", "pos")

dataplot3_1b = dataplot3_1b %>% mutate(perc_hd=pos/(pos+neg))

plot5 = ggplot(dataplot3_1b, aes(x=as.factor(heart_disease) ,
                         y=perc_hd*100, fill=as.factor(heart_disease ), 
                         group=as.factor(heart_disease ))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Heart disease",x="", y="Probability of stroke (%)", fill="Heart disease") +
  scale_fill_brewer(palette = "Dark2") + 
  scale_x_discrete(breaks=c("0","1"), labels=c("0" = "No HD", "1" = "HD")) + theme(legend.position = "none")+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))

```


```{r marital status}
#ever_married
dataplot3_1c=stroke_df %>% dplyr::count(stroke, ever_married) %>% spread(stroke, n)
names(dataplot3_1c)=c("ever_married", "neg", "pos")

dataplot3_1c = dataplot3_1c %>% mutate(perc_em=pos/(pos+neg))

plot6 = ggplot(dataplot3_1c, aes(x=ever_married ,
                         y=perc_em*100, fill=as.factor(ever_married ), 
                         group=as.factor(ever_married ))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Ever married",x="", y="Probability of stroke (%)", fill=" ") +
  scale_fill_brewer(palette = "Dark2") +
  theme(legend.position = "none")+ 
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))
```


```{r worktype}
# work type

dataplot3_1d= stroke_df %>% dplyr::count(stroke, work_type) %>% spread(stroke, n)
names(dataplot3_1d)=c("work_type", "neg", "pos")

dataplot3_1d = dataplot3_1d %>% mutate(perc_wt=pos/(pos+neg))

plot7=ggplot(dataplot3_1d %>% filter(work_type!="Never_worked"), aes(x=work_type ,
                         y=perc_wt*100, fill=as.factor(work_type ), 
                         group=as.factor(work_type ))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Work type",x=" ",y="Probability of stroke (%)", fill=" ") +
  scale_fill_brewer(palette = "Dark2") + 
  scale_x_discrete(labels=c("children" = "Children", "Govt_job" = "Gov. Job")) +
  theme(legend.position = "none")+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))
```


```{r}
#residence type

dataplot3_1e=stroke_df %>% dplyr::count(stroke, Residence_type) %>% spread(stroke, n)
names(dataplot3_1e)=c("Residence_type", "neg", "pos")

dataplot3_1e = dataplot3_1e %>% mutate(perc_rt=pos/(pos+neg))

plot8 = ggplot(dataplot3_1e, aes(x=Residence_type ,
                         y=perc_rt*100, fill=as.factor(Residence_type ), 
                         group=as.factor(Residence_type ))) + theme_bw()+
  geom_bar(stat = "identity")+
  labs(title="Residence type",x=" ", y="Probability of stroke (%)", fill=" ") +
  scale_fill_brewer(palette = "Dark2") +
  theme(legend.position = "none")+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))
```

Categorical variables:

```{r figures of distribution of categorical outcomes, fig.height = 20}
#figures
allplotslist_1 <- align_plots(plot2, plot3, plot4, plot5, plot6, plot7, plot8, align = "hv")


grid_1=grid.arrange(allplotslist_1[[1]],allplotslist_1[[2]],
                  allplotslist_1[[3]],allplotslist_1[[4]],
                  allplotslist_1[[5]], allplotslist_1[[6]],nrow = 3)
```


Continuous variable:

```{r continuous variable}
#age
plot9 = 
  stroke_df %>% 
  ggplot() + 
  geom_density(aes(x=age  , group=as.factor(stroke),fill=as.factor(stroke)),
               size=1,alpha=0.5, adjust=2)  + 
  theme_bw()+
  ylab("Density")+ labs(fill=' ',x="Age") +   
  scale_fill_brewer(palette = "Dark2",labels = c("No stroke", "Stroke"))+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))



# bmi
plot10 = 
  stroke_df %>% 
  ggplot() + 
  geom_density(aes(x=bmi, group=as.factor(stroke),fill=as.factor(stroke)),
               size=1,alpha=0.5, adjust=2)  + 
  theme_bw()+
  ylab("Density")+ labs(fill=' ',x="BMI") +   
  scale_fill_brewer(palette = "Dark2",labels = c("No stroke", "Stroke"))+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))



# avg_glucose_level
plot11 = 
  stroke_df %>% 
  ggplot() + 
  geom_density(aes(x=avg_glucose_level  , group=as.factor(stroke),fill=as.factor(stroke)),
               size=1,alpha=0.5, adjust=2)  + 
  theme_bw()+
  ylab("Density")+ labs(fill=' ',x="Avg. glucose level") +   
  scale_fill_brewer(palette = "Dark2",labels = c("No stroke", "Stroke"))+
  theme(text = element_text(size=13.07,colour="black"))+
  theme(axis.text.x = element_text(colour="black",size=13.07))+
  theme(axis.text.y = element_text(colour="black",size=13.07))

#combine plots

allplotslist_2 <- align_plots(plot9, plot10, plot11, align = "hv")

grid_3=grid.arrange(allplotslist_2[[1]],allplotslist_2[[2]],
                  allplotslist_2[[3]],ncol = 3)
```


**Comment**: From these plots we can see that:

Formerly smokers are more prone to suffer a stroke than smokers. This could be due to the fact that former smokers quit after acquiring health conditions that raised their risk of having a stroke.  

Self-employed are under higher risk of suffering a stroke than private and government jobs. Maybe due to higher stress and lack of insurance that are results of being self-employed?

Urban residents, males and people with hypertension or heart disease are prone to suffer a stroke. In addition, people who have been married are also more likely to suffer a stroke than the single people.

Age seems to be an important factor, with higher age comes higher chance of having a stroke. There are far more people who developed a stroke that have high glucose level than people with low glucose level. 

## Change categorical variables to binary for model training

```{r}

stroke_df$stroke = as.factor(stroke_df$stroke)
stroke_df$gender = factor(stroke_df$gender) %>% as.numeric()
stroke_df$ever_married = factor(stroke_df$ever_married) %>% as.numeric()
stroke_df$work_type = factor(stroke_df$work_type) %>% as.numeric()
stroke_df$Residence_type = factor(stroke_df$Residence_type) %>% as.numeric()
stroke_df$smoking_status = factor(stroke_df$smoking_status) %>% as.numeric()
stroke_df$heart_disease = factor(stroke_df$heart_disease) %>% as.numeric()
stroke_df$hypertension = as.numeric(factor(stroke_df$hypertension))
stroke_df$work_type = as.factor(stroke_df$work_type) %>% as.numeric()
stroke_df$bmi = as.numeric(stroke_df$bmi)

stroke_df = stroke_df[, -1] %>% 
    mutate(stroke = recode(stroke, 
                           `0` = "No", 
                           `1` = "Yes"), 
           stroke = factor(stroke)) %>% 
    filter(gender < 3) 


summary(stroke_df)
vis_miss(stroke_df)

head(stroke_df)
```



## Partition the dataset

```{r}
set.seed(123)
trRow = createDataPartition(y = stroke_df$stroke, p = 0.7, list = F)
train.data = stroke_df[trRow, ]
test.data = stroke_df[-trRow, ] 

```

## Imputation with `preProcess() `

```{r}
knnImp = preProcess(train.data, method = "knnImpute", k = 3)
train.data.imp = predict(knnImp, train.data)
vis_miss(train.data.imp)
test.data.imp = predict(knnImp,test.data)
vis_miss(test.data.imp)

```

Try following models to see which algorithm fits the best because our outcome is binary and it would better to proceed with which classification performs the best. We will have accuracy and ROC/AUC as our evaluation metrics.

In most cases I used grid search with repeated cross-validation (10 folds repeated 3 times) to tune the parameters. 

```{r}
ctrl <- trainControl(
  method = "repeatedcv", 
  number = 10,repeats=3,
  summaryFunction = twoClassSummary,
  classProbs = TRUE)
```


# Models

Try following models to see which algorithm fits the best because our outcome is binary and it would better to proceed with which classification performs the best. We will have accuracy and ROC/AUC as our evaluation metrics.

In most cases I used grid search with repeated cross-validation (10 folds repeated 3 times) to tune the parameters. 

## Logistic regression

### GLM

```{r glm}
# Using caret

set.seed(1)
model.glm <- train(x = train.data.imp[, c(1:10)],
                   y = train.data.imp$stroke,
                   method = "glm",
                   metric = "ROC",
                   trControl = ctrl)

summary(model.glm)

glm.pred = predict(model.glm, newdata = test.data.imp, type = "prob")

glm.prob = ifelse(glm.pred$Yes > 0.5,  "Yes", "No")

confusionMatrix(data = as.factor(glm.prob),
                reference = test.data.imp$stroke,
                positive = "Yes")

```


### Penalized logistic regression

```{r}

tune_grid = expand.grid(
  alpha=0:1,
  lambda = seq(0.0001, 1, length = 20)
)


model.logistic <- train(
  x = train.data.imp[, c(1:10)],
  y = train.data.imp$stroke,
  method = "glmnet",
  metric = "ROC",
  trControl = ctrl,
  tuneGrid = tune_grid)

log.pred = predict(model.logistic, newdata = test.data.imp, type = "prob")

log.prob = ifelse(log.pred$Yes > 0.5,  "Yes", "No")

confusionMatrix(data = as.factor(log.prob),
                reference = test.data.imp$stroke,
                positive = "Yes")

```




### KNN

```{r knn, echo = F, warning = F, message = F}
set.seed(1)


model.knn = train( x = train.data.imp[, c(1:10)],
                   y = train.data.imp$stroke,
                   method = "knn",
                   preProcess = c("center","scale"),
                   tuneGrid = data.frame(k = seq(1,200,by=5)),
                   trControl = ctrl)


model.knn$finalModel

knn.pred = predict(model.knn, newdata = test.data.imp, type = "prob")

knn.prob = ifelse(knn.pred$Yes > 0.5,  "Yes", "No")

confusionMatrix(data = as.factor(knn.prob),
                reference = test.data.imp$stroke,
                positive = "Yes")

```



### GAM

```{r gam}
set.seed(1)

model.gam <- train(x = train.data.imp[,c(1:10)],
                   y = train.data.imp$stroke,
                   method = "gam",
                   metric = "ROC",
                   trControl = ctrl)

summary(model.gam)

model.gam$finalModel


gam.pred = predict(model.gam, newdata = test.data.imp, type = "prob")

gam.prob = ifelse(gam.pred$Yes > 0.5,  "Yes", "No")

confusionMatrix(data = as.factor(gam.prob),
                reference = test.data.imp$stroke,
                positive = "Yes")


```


## Linear Discriminant Analysis (LDA)

```{r lda}
set.seed(1)
model.lda <- train(x = train.data.imp[,c(1:10)],
                   y = train.data.imp$stroke,
                   method = "lda",
                   metric = "ROC",
                   trControl = ctrl)

lda.pred = predict(model.lda, newdata = test.data.imp, type = "prob")

lda.prob = ifelse(lda.pred$Yes > 0.5,  "Yes", "No")


roc.lda <- roc(test.data.imp$stroke, lda.pred[,2])

auc.lda = roc.lda$auc[1]
auc.lda

plot(roc.lda, legacy.axes = TRUE, print.auc = TRUE)
plot(smooth(roc.lda), col = 4, add = TRUE)
     
confusionMatrix(data = as.factor(lda.prob),
                reference = test.data.imp$stroke,
                positive = "Yes")



```



## Classification trees

Logistic regression assumes that the data is linearly separable in space but decision trees do not. Decision trees also handle skewed data better. 


### Conditional Inference tree

```{r CIT}
set.seed(1)

#ctree.fit <- train(stroke ~ . ,  stroke_df,  subset = trRow,method = "ctree",metric = "ROC",trControl = ctrl,na.action = na.exclude)

#plot(ctree.fit$finalModel)

#ctree.pred <- predict(ctree.fit, newdata = stroke_df[-trRow,],type = "prob")[,1]

#roc.ctree <- roc(stroke_df$stroke[-trRow], ctree.pred)

#roc.ctree$auc[1]

#plot(roc.ctree, legacy.axes = TRUE, print.auc = TRUE)



model.ctree <- train(x = train.data.imp[,c(1:10)],
                   y = train.data.imp$stroke,
                   method = "ctree",
                   tuneGrid = data.frame(mincriterion = 1-exp(seq(-2, -1, length = 50))),
                   metric = "ROC",
                   trControl = ctrl)

model.ctree$finalModel #conditional inferece tree with 8 terminal nodes

plot(model.ctree$finalModel)




```

### CART

```{r rpart}
set.seed(1)
rpart.fit <- train(x = train.data.imp[,c(1:10)],
                   y = train.data.imp$stroke,
                   method = "rpart",
                   tuneGrid = data.frame(cp = exp(seq(-6,-3, len = 50))),
                   trControl = ctrl,
                   metric = "ROC")

rpart.fit
ggplot(rpart.fit, highlight = TRUE)
rpart.plot(rpart.fit$finalModel)

```


```{r}
summary(resamples(list(rpart.fit, model.ctree)))

#ctree is a better fit
```

### Bagging and Random Forests

```{r bagging and rf}
set.seed(1)

bagging <- randomForest(stroke ~ . , 
                        stroke_df[trRow,],
                        mtry = 8,
                        na.action = na.exclude)

set.seed(1)
rf <- randomForest(stroke ~ . , 
                   stroke_df[trRow,],
                   mtry = 3,
                   na.action = na.exclude)



varImpPlot(rf)
```

### Random forests using `caret`

```{r rf using caret}

rf.grid <- expand.grid(mtry = 1:8,
                       splitrule = "gini",
                       min.node.size = seq(from = 2, to = 10, by = 2))
set.seed(1)

rf.fit <- train(x = train.data.imp[,c(1:10)],
                   y = train.data.imp$stroke,
                method = "ranger",
                tuneGrid = rf.grid,
                metric = "ROC",
                trControl = ctrl)


#rf.pred = predict(rf.fit, newdata = test.data, type = "prob")

#rf.prob = ifelse(rf.pred$Yes > 0.5,  "Yes", "No")



#rf.prob = recode_factor(rf.prob, `0` = "No", `1` = "Yes")

#confusionMatrix(data = as.factor(rf.pred),reference = stroke_df$stroke[-trRow], positive = "Yes")

```



## SVM
Since we are considering the two-class classification problem in our context of question, SVM may serve as a good solution.

- What predictor variables did you include?

From the previous model, I decide to pick up features with variable importance greater than 10 : avg_glucose_level, age, bmi, smoking status and working type.

First of all, we will still process the model with all variables included in the model and plot the variable importance to see which variables should we keep in the model.

- What technique did you use? What assumptions, if any, are being made by using this technique?

The only assumptions of support vector machines are independent and identically distributed data. SVM is quite tolerant of input data, especially the soft-margin version.

- If there were tuning parameters, how did you pick their values?

C also known as cost parameter is the tuning parameter in the SVM algorithm. I will used the exponentiated sequence of number with cross-validation to see if there's any best parameters for this model. Plotting out the tuning will also help us have a better vizualization on deciding hyperparameters. 

### Linear SVM


### Radial SVM


```{r linear svm, eval = FALSE}

trainSmoted <- SMOTE(stroke ~ ., train.data)



trainSmoted$stroke = factor(trainSmoted$stroke, levels = c("No", "Yes"))
train.data$stroke = factor(train.data$stroke, levels = c("No", "Yes"))
test.data$stroke = factor(test.data$stroke, levels = c("No", "Yes"))

set.seed(123)

svm.linear = tune.svm(stroke ~ ., 
                      data = trainSmoted, 
                      kernel = "linear", 
                      cost = exp(seq(-5,2,len=50)),
                      scale = TRUE)



summary(svm.linear)
plot(svm.linear)

svm.linear$best.parameters

best.linear = svm.linear$best.model 
summary(best.linear)


pred_train_lsvm = predict(best.linear, newdata = train.data) 

pred_train_lsvm = recode_factor(pred_train_lsvm, `0` = "No", `1` = "Yes")

confusionMatrix(data = pred_train_lsvm, reference = train.data$stroke , positive = "Yes")

pred_test_lsvm = predict(best.linear, newdata = test.data)
confusionMatrix(data = pred_test_lsvm, reference = test.data$stroke, positive = "Yes")

pred_test_lsvm_numeric = as.numeric(pred_test_lsvm) -1
roc.lsvm = roc(test.data$stroke, pred_test_lsvm_numeric)

auc.lsvm = roc.lsvm$auc[1]
auc.lsvm
plot(roc.lsvm, legacy.axes = TRUE, print.auc = TRUE) 
# plot(smooth(roc.lsvm), col = 4, add = TRUE)
```

### Radial kernel (RBF)


```{r radial SVM, eval = FALSE}
set.seed(123)

svm.rbf = tune.svm(stroke ~ ., 
                      data = trainSmoted, 
                      kernel = "radial", 
                      cost = exp(seq(-4,1,len=10)),
                      gamma = exp(seq(-5,3,len = 10)))



summary(svm.rbf)
plot(svm.rbf)

svm.rbf$best.parameters

best.rbf = svm.rbf$best.model 
summary(best.rbf)

pred_train_rsvm = predict(best.rbf, newdata = train.data) 
confusionMatrix(data = pred_train_rsvm, reference = train.data$stroke, positive = "Yes")

pred_test_rsvm = predict(best.rbf, newdata = test.data) 
confusionMatrix(data = pred_test_rsvm, reference = test.data$stroke, positive = "Yes")

pred_test_rsvm_numeric = as.numeric(pred_test_rsvm) -1
roc.rsvm = roc(test.data$stroke, pred_test_rsvm_numeric)

auc.rsvm = roc.rsvm$auc[1]
auc.rsvm
plot(roc.rsvm, legacy.axes = TRUE, print.auc = TRUE) 
# plot(smooth(roc.rsvm), col = 4, add = TRUE)
```





## Compare models


```{r comparing using cv}
# based on cv

res <- resamples(list(glm = model.glm,  
                      gam = model.gam,
                      knn = model.knn,
                      lda = model.lda,
                      cart = rpart.fit, 
                      cit = model.ctree,
                      rf = rf.fit))
summary(res) 

bwplot(res, metric = "ROC")

# GLM and GAM perform better compared to KNN. KNN usually requires a larger dataset to perform as good as model with symmeratric structure. 


```


```{r auc}
#1st column is probability of negative, 2nd is positive
glm.pred <- predict(model.glm, newdata = test.data.imp, type = "prob")[,2]
gam.pred <- predict(model.gam, newdata = test.data.imp, type = "prob")[,2]
lda.pred <- predict(model.lda, newdata = test.data.imp, type = "prob")[,2]
knn.pred <- predict(model.knn, newdata = test.data.imp, type = "prob")[,2]
rf.pred <- predict(rf.fit, newdata = test.data.imp, type = "prob")[,2]
cit.pred <- predict(model.ctree, newdata = test.data.imp, type = "prob")[,2]
cart.pred <- predict(rpart.fit, newdata = test.data.imp, type = "prob")[,2]

roc.glm <- roc(test.data.imp$stroke, glm.pred)
roc.gam <- roc(test.data.imp$stroke, gam.pred)
roc.lda <- roc(test.data.imp$stroke, lda.pred)
roc.knn <- roc(test.data.imp$stroke, knn.pred)
roc.rf <- roc(test.data.imp$stroke, rf.pred)
roc.cit <- roc(test.data.imp$stroke, cit.pred)
roc.cart <- roc(test.data.imp$stroke, cart.pred)


auc <- c(roc.glm$auc[1], roc.gam$auc[1],
         roc.lda$auc[1], roc.knn$auc[1],
         roc.rf$auc[1], roc.cit$auc[1],
         roc.cart$auc[1])

plot(roc.glm, legacy.axes = TRUE)
plot(roc.gam, col = 2, add = TRUE)
plot(roc.lda, col = 3, add = TRUE)
plot(roc.knn, col = 4, add = TRUE)
plot(roc.rf, col = 5, add = TRUE)
plot(roc.cit, col = 6, add = TRUE)
plot(roc.cart, col = 7, add = TRUE)

modelNames <- c("glm", "gam","lda", "knn","rf", "cit", "cart")
legend("bottomright", legend = paste0(modelNames, ": ", round(auc,3)),
       col = 1:7, lwd = 2)
```


# Conclusion
We could fix this by ovesampling, however,for the purpose of our analysis, I opted to evaluate normal sampling data to avoid biased prediction results.The linear discriminant model would be more stable than the logistic regresion model if the distribution of the predictors is approximately normal, which is not the case in this example. LDA is also more popular when we have more than two response classes.

# Variable Importance

```{r}
varImp(model.glm)

 

```



